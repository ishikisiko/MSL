{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a3b82e4",
   "metadata": {},
   "source": [
    "# MLS3 Hardware-Aware Design - Colab 运行环境\n",
    "\n",
    "这个 notebook 提供了在 Google Colab 上运行 MLS3 多文件项目的完整设置流程。\n",
    "\n",
    "## 🚀 快速开始\n",
    "\n",
    "按顺序运行以下单元格即可完成整个流程：\n",
    "1. 从 GitHub 克隆项目\n",
    "2. 环境设置和依赖安装\n",
    "3. 训练基线模型（可选，如果已有模型）\n",
    "4. 运行优化流程\n",
    "5. 查看结果和下载输出\n",
    "\n",
    "## 📋 项目仓库\n",
    "\n",
    "- **GitHub**: https://github.com/ishikisiko/MSL.git\n",
    "- **项目路径**: MSL/MLS3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428072d7",
   "metadata": {},
   "source": [
    "## 📥 步骤 1: 从 GitHub 克隆项目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a75088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 克隆项目仓库\n",
    "print(\"正在从 GitHub 克隆项目...\")\n",
    "!git clone https://github.com/ishikisiko/MSL.git\n",
    "print(\"✓ 克隆完成\")\n",
    "\n",
    "# 切换到 MLS3 目录\n",
    "%cd MSL/MLS3\n",
    "\n",
    "# 显示当前目录内容\n",
    "print(\"\\n当前目录内容：\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3e2fb1",
   "metadata": {},
   "source": [
    "## 🔧 步骤 2: 环境设置和依赖安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cc5a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查当前目录和文件\n",
    "!pwd\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f27825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装依赖（使用项目的 requirements.txt）\n",
    "print(\"安装 Python 依赖包...\")\n",
    "\n",
    "print(\"步骤 1/2: 升级 pip 以获取兼容 wheel...\")\n",
    "!python -m pip install --upgrade pip\n",
    "\n",
    "print(\"步骤 2/2: 安装项目锁定的依赖...\")\n",
    "!python -m pip install --quiet -r requirements.txt\n",
    "# 可选：仅当计划使用 %lprun profiling magic 时安装 line_profiler\n",
    "# !python -m pip install --quiet line_profiler\n",
    "\n",
    "# 验证安装\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "print(\"\\n✓ 依赖安装完成\")\n",
    "print(f\"✓ NumPy: {np.__version__} (需求: 1.26.4)\")\n",
    "print(f\"✓ TensorFlow: {tf.__version__} (需求: 2.15.1)\")\n",
    "print(f\"✓ TF-MOT: {tfmot.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b829590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查 GPU 可用性\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow 版本:\", tf.__version__)\n",
    "print(\"GPU 可用:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"\\n✓ GPU 已启用，训练将更快！\")\n",
    "    # 设置内存增长\n",
    "    for gpu in tf.config.list_physical_devices('GPU'):\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "else:\n",
    "    print(\"\\n⚠ 未检测到 GPU，将使用 CPU 运行\")\n",
    "    print(\"建议：在 Colab 菜单中选择 '运行时' -> '更改运行时类型' -> 选择 GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eae3751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 快速测试模块导入\n",
    "print(\"测试模块导入...\\n\")\n",
    "\n",
    "try:\n",
    "    import part1_baseline_model\n",
    "    print(\"✓ part1_baseline_model 导入成功\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ part1_baseline_model 导入失败: {e}\")\n",
    "\n",
    "try:\n",
    "    import part2_optimizations\n",
    "    print(\"✓ part2_optimizations 导入成功\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ part2_optimizations 导入失败: {e}\")\n",
    "\n",
    "try:\n",
    "    import performance_profiler\n",
    "    print(\"✓ performance_profiler 导入成功\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ performance_profiler 导入失败: {e}\")\n",
    "\n",
    "try:\n",
    "    import part3_modeling\n",
    "    print(\"✓ part3_modeling 导入成功\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ part3_modeling 导入失败: {e}\")\n",
    "\n",
    "try:\n",
    "    import part3_deployment\n",
    "    print(\"✓ part3_deployment 导入成功\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ part3_deployment 导入失败: {e}\")\n",
    "\n",
    "print(\"\\n✓ 所有模块导入完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3634b1cc",
   "metadata": {},
   "source": [
    "## 🎯 步骤 3: 训练基线模型（可选）\n",
    "\n",
    "如果你已经有训练好的 `baseline_mobilenetv2.keras` 文件，可以跳过这一步。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8b8841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查是否已有基线模型\n",
    "import os\n",
    "\n",
    "if os.path.exists('baseline_mobilenetv2.keras'):\n",
    "    print(\"✓ 发现已训练的基线模型，跳过训练步骤\")\n",
    "    SKIP_TRAINING = True\n",
    "else:\n",
    "    print(\"⚠ 未发现基线模型，需要训练\")\n",
    "    SKIP_TRAINING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594ccebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练基线模型（如果需要）\n",
    "# 警告：这将花费 30-60 分钟！\n",
    "\n",
    "if not SKIP_TRAINING:\n",
    "    print(\"开始训练基线模型...\")\n",
    "    print(\"预计时间：30-60 分钟（使用 GPU）\")\n",
    "    print(\"\\n你可以选择：\")\n",
    "    print(\"1. 等待完整训练完成（推荐）\")\n",
    "    print(\"2. 或者在本地训练后上传 baseline_mobilenetv2.keras 文件\")\n",
    "    \n",
    "    # 运行训练\n",
    "    !python part1_baseline_model.py\n",
    "    \n",
    "    print(\"\\n✓ 基线模型训练完成\")\n",
    "else:\n",
    "    print(\"跳过训练步骤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757d96e5",
   "metadata": {},
   "source": [
    "## ⚙️ 步骤 4: 运行完整优化流程\n",
    "\n",
    "这将执行以下操作：\n",
    "1. 创建三种优化模型（延迟/内存/能耗）\n",
    "2. 应用量化技术\n",
    "3. 性能基准测试\n",
    "4. 生成对比报告\n",
    "5. Track B 仿真演示\n",
    "6. Track A 部署转换演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e7b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行完整优化流程\n",
    "# 预计时间：20-40 分钟\n",
    "\n",
    "print(\"开始运行优化流程...\")\n",
    "print(\"预计时间：20-40 分钟\\n\")\n",
    "\n",
    "!python run_optimizations.py\n",
    "\n",
    "print(\"\\n✓ 优化流程完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7329e77",
   "metadata": {},
   "source": [
    "## 📊 步骤 5: 查看结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cca9ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列出生成的文件\n",
    "print(\"生成的优化模型：\")\n",
    "!ls -lh optimized_models/\n",
    "\n",
    "print(\"\\n结果文件：\")\n",
    "!ls -lh results/\n",
    "\n",
    "print(\"\\n日志文件：\")\n",
    "!ls -lh logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920461b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 快速性能对比可视化\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 示例数据（实际数据将从运行结果中提取）\n",
    "models = ['Baseline', 'Latency\\nOptimized', 'Memory\\nOptimized', 'Energy\\nOptimized']\n",
    "\n",
    "# 创建子图\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 模型大小对比\n",
    "ax = axes[0, 0]\n",
    "sizes = [100, 50, 25, 60]  # 示例数据\n",
    "ax.bar(models, sizes, color=['#3498db', '#2ecc71', '#e74c3c', '#f39c12'])\n",
    "ax.set_ylabel('Model Size (MB)')\n",
    "ax.set_title('Model Size Comparison')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 延迟对比\n",
    "ax = axes[0, 1]\n",
    "latencies = [100, 45, 70, 55]  # 示例数据\n",
    "ax.bar(models, latencies, color=['#3498db', '#2ecc71', '#e74c3c', '#f39c12'])\n",
    "ax.set_ylabel('Latency (ms)')\n",
    "ax.set_title('Inference Latency Comparison')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 能耗对比\n",
    "ax = axes[1, 0]\n",
    "energy = [100, 60, 75, 40]  # 示例数据\n",
    "ax.bar(models, energy, color=['#3498db', '#2ecc71', '#e74c3c', '#f39c12'])\n",
    "ax.set_ylabel('Energy (mJ)')\n",
    "ax.set_title('Energy Consumption Comparison')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 准确率对比\n",
    "ax = axes[1, 1]\n",
    "accuracy = [85.5, 83.2, 81.0, 84.1]  # 示例数据\n",
    "ax.bar(models, accuracy, color=['#3498db', '#2ecc71', '#e74c3c', '#f39c12'])\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_title('Classification Accuracy Comparison')\n",
    "ax.set_ylim([75, 90])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/performance_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ 性能对比图已保存到 results/performance_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5160dc29",
   "metadata": {},
   "source": [
    "## 💾 步骤 6: 下载结果文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2be3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打包所有结果文件\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "archive_name = f\"MLS3_results_{timestamp}\"\n",
    "\n",
    "print(\"打包结果文件...\")\n",
    "\n",
    "# 创建临时目录\n",
    "!mkdir -p /content/export/{archive_name}\n",
    "\n",
    "# 复制重要文件\n",
    "!cp -r optimized_models /content/export/{archive_name}/\n",
    "!cp -r results /content/export/{archive_name}/\n",
    "!cp -r logs /content/export/{archive_name}/\n",
    "!cp baseline_mobilenetv2.keras /content/export/{archive_name}/ 2>/dev/null || true\n",
    "\n",
    "# 创建 ZIP 文件\n",
    "%cd /content/export\n",
    "!zip -r {archive_name}.zip {archive_name}\n",
    "%cd /content/MLS3\n",
    "\n",
    "print(f\"\\n✓ 结果已打包到: /content/export/{archive_name}.zip\")\n",
    "print(f\"文件大小: \", end=\"\")\n",
    "!du -h /content/export/{archive_name}.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1749894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载结果压缩包\n",
    "from google.colab import files\n",
    "\n",
    "zip_path = f\"/content/export/{archive_name}.zip\"\n",
    "print(f\"下载 {archive_name}.zip...\")\n",
    "files.download(zip_path)\n",
    "print(\"\\n✓ 下载完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6c2691",
   "metadata": {},
   "source": [
    "## 🔍 单独运行特定部分（可选）\n",
    "\n",
    "如果你只想运行某个特定部分，可以使用以下单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64e851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选项 A: 仅创建优化模型\n",
    "from part2_optimizations import (\n",
    "    create_latency_optimized_model,\n",
    "    create_memory_optimized_model,\n",
    "    create_energy_optimized_model\n",
    ")\n",
    "\n",
    "# 创建延迟优化模型\n",
    "latency_model = create_latency_optimized_model(\n",
    "    input_shape=(128, 128, 3),\n",
    "    num_classes=10,\n",
    "    alpha=0.5\n",
    ")\n",
    "print(\"✓ 延迟优化模型已创建\")\n",
    "\n",
    "# 查看模型架构\n",
    "latency_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f4e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选项 B: 仅量化模型\n",
    "from part2_optimizations import dynamic_range_quantization\n",
    "from tensorflow import keras\n",
    "\n",
    "# 加载模型\n",
    "model = keras.models.load_model('baseline_mobilenetv2.keras')\n",
    "\n",
    "# 应用动态量化\n",
    "dynamic_range_quantization(model, save_path='optimized_models/test_quantized.tflite')\n",
    "print(\"✓ 量化完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73676099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选项 C: 仅性能分析\n",
    "from performance_profiler import profile_model_comprehensive, print_profiling_results\n",
    "from tensorflow import keras\n",
    "from part1_baseline_model import load_and_preprocess_data\n",
    "\n",
    "# 加载模型和数据\n",
    "model = keras.models.load_model('baseline_mobilenetv2.keras')\n",
    "_, _, test_ds = load_and_preprocess_data(batch_size=64)\n",
    "\n",
    "# 性能分析\n",
    "platform_config = {\n",
    "    \"power_budget_w\": 5.0,\n",
    "    \"memory_budget_mb\": 1024,\n",
    "    \"tdp_watts\": 10.0,\n",
    "}\n",
    "\n",
    "results = profile_model_comprehensive(model, test_ds, platform_config)\n",
    "print_profiling_results(results, \"Baseline Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00efae7",
   "metadata": {},
   "source": [
    "## 📝 生成分析报告\n",
    "\n",
    "根据运行结果生成 Part 4 分析报告的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd8ccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 汇总关键指标\n",
    "import json\n",
    "\n",
    "summary = {\n",
    "    \"project\": \"MLS3 Hardware-Aware Design\",\n",
    "    \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "    \"models\": [\n",
    "        {\"name\": \"baseline\", \"path\": \"baseline_mobilenetv2.keras\"},\n",
    "        {\"name\": \"latency_optimized\", \"path\": \"optimized_models/latency_optimized.keras\"},\n",
    "        {\"name\": \"memory_optimized\", \"path\": \"optimized_models/memory_optimized.keras\"},\n",
    "        {\"name\": \"energy_optimized\", \"path\": \"optimized_models/energy_optimized.keras\"},\n",
    "    ],\n",
    "    \"quantized_models\": [\n",
    "        {\"name\": \"dynamic_quantization\", \"path\": \"optimized_models/latency_optimized_dynamic.tflite\"},\n",
    "        {\"name\": \"ptq_int8\", \"path\": \"optimized_models/latency_optimized_ptq_int8.tflite\"},\n",
    "    ],\n",
    "    \"deployment\": [\n",
    "        {\"name\": \"tflite\", \"path\": \"optimized_models/baseline.tflite\"},\n",
    "        {\"name\": \"tflite_micro\", \"path\": \"optimized_models/baseline_data.cc\"},\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 保存摘要\n",
    "with open('results/project_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"✓ 项目摘要已保存到 results/project_summary.json\")\n",
    "print(\"\\n摘要内容：\")\n",
    "print(json.dumps(summary, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0c3049",
   "metadata": {},
   "source": [
    "## 🎉 完成！\n",
    "\n",
    "### 生成的文件：\n",
    "\n",
    "**优化模型：**\n",
    "- `optimized_models/latency_optimized.keras` - 延迟优化模型\n",
    "- `optimized_models/memory_optimized.keras` - 内存优化模型\n",
    "- `optimized_models/energy_optimized.keras` - 能耗优化模型\n",
    "\n",
    "**量化模型：**\n",
    "- `optimized_models/*_dynamic.tflite` - 动态量化模型\n",
    "- `optimized_models/*_ptq_int8.tflite` - INT8 PTQ 模型\n",
    "\n",
    "**部署文件：**\n",
    "- `optimized_models/*.tflite` - TFLite 格式\n",
    "- `optimized_models/*_data.cc` - TFLite Micro C 数组\n",
    "\n",
    "**结果和日志：**\n",
    "- `results/` - 性能指标和对比报告\n",
    "- `logs/` - 训练和执行日志\n",
    "\n",
    "### 下一步：\n",
    "1. 下载所有结果文件（已打包到 ZIP）\n",
    "2. 分析性能对比数据\n",
    "3. 编写 Part 4 综合分析报告\n",
    "4. 准备演示材料\n",
    "\n",
    "### 提示：\n",
    "- 使用 `files.download()` 下载单个文件\n",
    "- 所有结果已打包到 ZIP 文件中\n",
    "- 可以在 Colab 文件浏览器中查看所有生成的文件\n",
    "- 如需重新运行，请 \"运行时\" -> \"重启并运行所有单元格\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
