{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a3b82e4",
   "metadata": {},
   "source": [
    "# MLS3 Hardware-Aware Design - Colab è¿è¡Œç¯å¢ƒ\n",
    "\n",
    "è¿™ä¸ª notebook æä¾›äº†åœ¨ Google Colab ä¸Šè¿è¡Œ MLS3 å¤šæ–‡ä»¶é¡¹ç›®çš„å®Œæ•´è®¾ç½®æµç¨‹ã€‚\n",
    "\n",
    "## ğŸš€ å¿«é€Ÿå¼€å§‹\n",
    "\n",
    "æŒ‰é¡ºåºè¿è¡Œä»¥ä¸‹å•å…ƒæ ¼å³å¯å®Œæˆæ•´ä¸ªæµç¨‹ï¼š\n",
    "1. ä» GitHub å…‹éš†é¡¹ç›®\n",
    "2. ç¯å¢ƒè®¾ç½®å’Œä¾èµ–å®‰è£…\n",
    "3. è®­ç»ƒåŸºçº¿æ¨¡å‹ï¼ˆå¯é€‰ï¼Œå¦‚æœå·²æœ‰æ¨¡å‹ï¼‰\n",
    "4. è¿è¡Œä¼˜åŒ–æµç¨‹\n",
    "5. æŸ¥çœ‹ç»“æœå’Œä¸‹è½½è¾“å‡º\n",
    "\n",
    "## ğŸ“‹ é¡¹ç›®ä»“åº“\n",
    "\n",
    "- **GitHub**: https://github.com/ishikisiko/MSL.git\n",
    "- **é¡¹ç›®è·¯å¾„**: MSL/MLS3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428072d7",
   "metadata": {},
   "source": [
    "## ğŸ“¥ æ­¥éª¤ 1: ä» GitHub å…‹éš†é¡¹ç›®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a75088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å…‹éš†é¡¹ç›®ä»“åº“\n",
    "print(\"æ­£åœ¨ä» GitHub å…‹éš†é¡¹ç›®...\")\n",
    "!git clone https://github.com/ishikisiko/MSL.git\n",
    "print(\"âœ“ å…‹éš†å®Œæˆ\")\n",
    "\n",
    "# åˆ‡æ¢åˆ° MLS3 ç›®å½•\n",
    "%cd MSL/MLS3\n",
    "\n",
    "# æ˜¾ç¤ºå½“å‰ç›®å½•å†…å®¹\n",
    "print(\"\\nå½“å‰ç›®å½•å†…å®¹ï¼š\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3e2fb1",
   "metadata": {},
   "source": [
    "## ğŸ”§ æ­¥éª¤ 2: ç¯å¢ƒè®¾ç½®å’Œä¾èµ–å®‰è£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cc5a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥å½“å‰ç›®å½•å’Œæ–‡ä»¶\n",
    "!pwd\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f27825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…ä¾èµ–ï¼ˆä½¿ç”¨é¡¹ç›®çš„ requirements.txtï¼‰\n",
    "print(\"å®‰è£… Python ä¾èµ–åŒ…...\")\n",
    "\n",
    "print(\"æ­¥éª¤ 1/2: å‡çº§ pip ä»¥è·å–å…¼å®¹ wheel...\")\n",
    "!python -m pip install --upgrade pip\n",
    "\n",
    "print(\"æ­¥éª¤ 2/2: å®‰è£…é¡¹ç›®é”å®šçš„ä¾èµ–...\")\n",
    "!python -m pip install --quiet -r requirements.txt\n",
    "# å¯é€‰ï¼šä»…å½“è®¡åˆ’ä½¿ç”¨ %lprun profiling magic æ—¶å®‰è£… line_profiler\n",
    "# !python -m pip install --quiet line_profiler\n",
    "\n",
    "# éªŒè¯å®‰è£…\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "print(\"\\nâœ“ ä¾èµ–å®‰è£…å®Œæˆ\")\n",
    "print(f\"âœ“ NumPy: {np.__version__} (éœ€æ±‚: 1.26.4)\")\n",
    "print(f\"âœ“ TensorFlow: {tf.__version__} (éœ€æ±‚: 2.15.1)\")\n",
    "print(f\"âœ“ TF-MOT: {tfmot.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b829590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥ GPU å¯ç”¨æ€§\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow ç‰ˆæœ¬:\", tf.__version__)\n",
    "print(\"GPU å¯ç”¨:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"\\nâœ“ GPU å·²å¯ç”¨ï¼Œè®­ç»ƒå°†æ›´å¿«ï¼\")\n",
    "    # è®¾ç½®å†…å­˜å¢é•¿\n",
    "    for gpu in tf.config.list_physical_devices('GPU'):\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "else:\n",
    "    print(\"\\nâš  æœªæ£€æµ‹åˆ° GPUï¼Œå°†ä½¿ç”¨ CPU è¿è¡Œ\")\n",
    "    print(\"å»ºè®®ï¼šåœ¨ Colab èœå•ä¸­é€‰æ‹© 'è¿è¡Œæ—¶' -> 'æ›´æ”¹è¿è¡Œæ—¶ç±»å‹' -> é€‰æ‹© GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eae3751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿«é€Ÿæµ‹è¯•æ¨¡å—å¯¼å…¥\n",
    "print(\"æµ‹è¯•æ¨¡å—å¯¼å…¥...\\n\")\n",
    "\n",
    "try:\n",
    "    import part1_baseline_model\n",
    "    print(\"âœ“ part1_baseline_model å¯¼å…¥æˆåŠŸ\")\n",
    "except ImportError as e:\n",
    "    print(f\"âœ— part1_baseline_model å¯¼å…¥å¤±è´¥: {e}\")\n",
    "\n",
    "try:\n",
    "    import part2_optimizations\n",
    "    print(\"âœ“ part2_optimizations å¯¼å…¥æˆåŠŸ\")\n",
    "except ImportError as e:\n",
    "    print(f\"âœ— part2_optimizations å¯¼å…¥å¤±è´¥: {e}\")\n",
    "\n",
    "try:\n",
    "    import performance_profiler\n",
    "    print(\"âœ“ performance_profiler å¯¼å…¥æˆåŠŸ\")\n",
    "except ImportError as e:\n",
    "    print(f\"âœ— performance_profiler å¯¼å…¥å¤±è´¥: {e}\")\n",
    "\n",
    "try:\n",
    "    import part3_modeling\n",
    "    print(\"âœ“ part3_modeling å¯¼å…¥æˆåŠŸ\")\n",
    "except ImportError as e:\n",
    "    print(f\"âœ— part3_modeling å¯¼å…¥å¤±è´¥: {e}\")\n",
    "\n",
    "try:\n",
    "    import part3_deployment\n",
    "    print(\"âœ“ part3_deployment å¯¼å…¥æˆåŠŸ\")\n",
    "except ImportError as e:\n",
    "    print(f\"âœ— part3_deployment å¯¼å…¥å¤±è´¥: {e}\")\n",
    "\n",
    "print(\"\\nâœ“ æ‰€æœ‰æ¨¡å—å¯¼å…¥å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3634b1cc",
   "metadata": {},
   "source": [
    "## ğŸ¯ æ­¥éª¤ 3: è®­ç»ƒåŸºçº¿æ¨¡å‹ï¼ˆå¯é€‰ï¼‰\n",
    "\n",
    "å¦‚æœä½ å·²ç»æœ‰è®­ç»ƒå¥½çš„ `baseline_mobilenetv2.keras` æ–‡ä»¶ï¼Œå¯ä»¥è·³è¿‡è¿™ä¸€æ­¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8b8841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥æ˜¯å¦å·²æœ‰åŸºçº¿æ¨¡å‹\n",
    "import os\n",
    "\n",
    "if os.path.exists('baseline_mobilenetv2.keras'):\n",
    "    print(\"âœ“ å‘ç°å·²è®­ç»ƒçš„åŸºçº¿æ¨¡å‹ï¼Œè·³è¿‡è®­ç»ƒæ­¥éª¤\")\n",
    "    SKIP_TRAINING = True\n",
    "else:\n",
    "    print(\"âš  æœªå‘ç°åŸºçº¿æ¨¡å‹ï¼Œéœ€è¦è®­ç»ƒ\")\n",
    "    SKIP_TRAINING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594ccebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒåŸºçº¿æ¨¡å‹ï¼ˆå¦‚æœéœ€è¦ï¼‰\n",
    "# è­¦å‘Šï¼šè¿™å°†èŠ±è´¹ 30-60 åˆ†é’Ÿï¼\n",
    "\n",
    "if not SKIP_TRAINING:\n",
    "    print(\"å¼€å§‹è®­ç»ƒåŸºçº¿æ¨¡å‹...\")\n",
    "    print(\"é¢„è®¡æ—¶é—´ï¼š30-60 åˆ†é’Ÿï¼ˆä½¿ç”¨ GPUï¼‰\")\n",
    "    print(\"\\nä½ å¯ä»¥é€‰æ‹©ï¼š\")\n",
    "    print(\"1. ç­‰å¾…å®Œæ•´è®­ç»ƒå®Œæˆï¼ˆæ¨èï¼‰\")\n",
    "    print(\"2. æˆ–è€…åœ¨æœ¬åœ°è®­ç»ƒåä¸Šä¼  baseline_mobilenetv2.keras æ–‡ä»¶\")\n",
    "    \n",
    "    # è¿è¡Œè®­ç»ƒ\n",
    "    !python part1_baseline_model.py\n",
    "    \n",
    "    print(\"\\nâœ“ åŸºçº¿æ¨¡å‹è®­ç»ƒå®Œæˆ\")\n",
    "else:\n",
    "    print(\"è·³è¿‡è®­ç»ƒæ­¥éª¤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757d96e5",
   "metadata": {},
   "source": [
    "## âš™ï¸ æ­¥éª¤ 4: è¿è¡Œå®Œæ•´ä¼˜åŒ–æµç¨‹\n",
    "\n",
    "è¿™å°†æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š\n",
    "1. åˆ›å»ºä¸‰ç§ä¼˜åŒ–æ¨¡å‹ï¼ˆå»¶è¿Ÿ/å†…å­˜/èƒ½è€—ï¼‰\n",
    "2. åº”ç”¨é‡åŒ–æŠ€æœ¯\n",
    "3. æ€§èƒ½åŸºå‡†æµ‹è¯•\n",
    "4. ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š\n",
    "5. Track B ä»¿çœŸæ¼”ç¤º\n",
    "6. Track A éƒ¨ç½²è½¬æ¢æ¼”ç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e7b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿è¡Œå®Œæ•´ä¼˜åŒ–æµç¨‹\n",
    "# é¢„è®¡æ—¶é—´ï¼š20-40 åˆ†é’Ÿ\n",
    "\n",
    "print(\"å¼€å§‹è¿è¡Œä¼˜åŒ–æµç¨‹...\")\n",
    "print(\"é¢„è®¡æ—¶é—´ï¼š20-40 åˆ†é’Ÿ\\n\")\n",
    "\n",
    "!python run_optimizations.py\n",
    "\n",
    "print(\"\\nâœ“ ä¼˜åŒ–æµç¨‹å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7329e77",
   "metadata": {},
   "source": [
    "## ğŸ“Š æ­¥éª¤ 5: æŸ¥çœ‹ç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cca9ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ—å‡ºç”Ÿæˆçš„æ–‡ä»¶\n",
    "print(\"ç”Ÿæˆçš„ä¼˜åŒ–æ¨¡å‹ï¼š\")\n",
    "!ls -lh optimized_models/\n",
    "\n",
    "print(\"\\nç»“æœæ–‡ä»¶ï¼š\")\n",
    "!ls -lh results/\n",
    "\n",
    "print(\"\\næ—¥å¿—æ–‡ä»¶ï¼š\")\n",
    "!ls -lh logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920461b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿«é€Ÿæ€§èƒ½å¯¹æ¯”å¯è§†åŒ–\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ç¤ºä¾‹æ•°æ®ï¼ˆå®é™…æ•°æ®å°†ä»è¿è¡Œç»“æœä¸­æå–ï¼‰\n",
    "models = ['Baseline', 'Latency\\nOptimized', 'Memory\\nOptimized', 'Energy\\nOptimized']\n",
    "\n",
    "# åˆ›å»ºå­å›¾\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# æ¨¡å‹å¤§å°å¯¹æ¯”\n",
    "ax = axes[0, 0]\n",
    "sizes = [100, 50, 25, 60]  # ç¤ºä¾‹æ•°æ®\n",
    "ax.bar(models, sizes, color=['#3498db', '#2ecc71', '#e74c3c', '#f39c12'])\n",
    "ax.set_ylabel('Model Size (MB)')\n",
    "ax.set_title('Model Size Comparison')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# å»¶è¿Ÿå¯¹æ¯”\n",
    "ax = axes[0, 1]\n",
    "latencies = [100, 45, 70, 55]  # ç¤ºä¾‹æ•°æ®\n",
    "ax.bar(models, latencies, color=['#3498db', '#2ecc71', '#e74c3c', '#f39c12'])\n",
    "ax.set_ylabel('Latency (ms)')\n",
    "ax.set_title('Inference Latency Comparison')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# èƒ½è€—å¯¹æ¯”\n",
    "ax = axes[1, 0]\n",
    "energy = [100, 60, 75, 40]  # ç¤ºä¾‹æ•°æ®\n",
    "ax.bar(models, energy, color=['#3498db', '#2ecc71', '#e74c3c', '#f39c12'])\n",
    "ax.set_ylabel('Energy (mJ)')\n",
    "ax.set_title('Energy Consumption Comparison')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# å‡†ç¡®ç‡å¯¹æ¯”\n",
    "ax = axes[1, 1]\n",
    "accuracy = [85.5, 83.2, 81.0, 84.1]  # ç¤ºä¾‹æ•°æ®\n",
    "ax.bar(models, accuracy, color=['#3498db', '#2ecc71', '#e74c3c', '#f39c12'])\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_title('Classification Accuracy Comparison')\n",
    "ax.set_ylim([75, 90])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/performance_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ æ€§èƒ½å¯¹æ¯”å›¾å·²ä¿å­˜åˆ° results/performance_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5160dc29",
   "metadata": {},
   "source": [
    "## ğŸ’¾ æ­¥éª¤ 6: ä¸‹è½½ç»“æœæ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2be3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰“åŒ…æ‰€æœ‰ç»“æœæ–‡ä»¶\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "archive_name = f\"MLS3_results_{timestamp}\"\n",
    "\n",
    "print(\"æ‰“åŒ…ç»“æœæ–‡ä»¶...\")\n",
    "\n",
    "# åˆ›å»ºä¸´æ—¶ç›®å½•\n",
    "!mkdir -p /content/export/{archive_name}\n",
    "\n",
    "# å¤åˆ¶é‡è¦æ–‡ä»¶\n",
    "!cp -r optimized_models /content/export/{archive_name}/\n",
    "!cp -r results /content/export/{archive_name}/\n",
    "!cp -r logs /content/export/{archive_name}/\n",
    "!cp baseline_mobilenetv2.keras /content/export/{archive_name}/ 2>/dev/null || true\n",
    "\n",
    "# åˆ›å»º ZIP æ–‡ä»¶\n",
    "%cd /content/export\n",
    "!zip -r {archive_name}.zip {archive_name}\n",
    "%cd /content/MLS3\n",
    "\n",
    "print(f\"\\nâœ“ ç»“æœå·²æ‰“åŒ…åˆ°: /content/export/{archive_name}.zip\")\n",
    "print(f\"æ–‡ä»¶å¤§å°: \", end=\"\")\n",
    "!du -h /content/export/{archive_name}.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1749894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸‹è½½ç»“æœå‹ç¼©åŒ…\n",
    "from google.colab import files\n",
    "\n",
    "zip_path = f\"/content/export/{archive_name}.zip\"\n",
    "print(f\"ä¸‹è½½ {archive_name}.zip...\")\n",
    "files.download(zip_path)\n",
    "print(\"\\nâœ“ ä¸‹è½½å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6c2691",
   "metadata": {},
   "source": [
    "## ğŸ” å•ç‹¬è¿è¡Œç‰¹å®šéƒ¨åˆ†ï¼ˆå¯é€‰ï¼‰\n",
    "\n",
    "å¦‚æœä½ åªæƒ³è¿è¡ŒæŸä¸ªç‰¹å®šéƒ¨åˆ†ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å•å…ƒæ ¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64e851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é€‰é¡¹ A: ä»…åˆ›å»ºä¼˜åŒ–æ¨¡å‹\n",
    "from part2_optimizations import (\n",
    "    create_latency_optimized_model,\n",
    "    create_memory_optimized_model,\n",
    "    create_energy_optimized_model\n",
    ")\n",
    "\n",
    "# åˆ›å»ºå»¶è¿Ÿä¼˜åŒ–æ¨¡å‹\n",
    "latency_model = create_latency_optimized_model(\n",
    "    input_shape=(128, 128, 3),\n",
    "    num_classes=10,\n",
    "    alpha=0.5\n",
    ")\n",
    "print(\"âœ“ å»¶è¿Ÿä¼˜åŒ–æ¨¡å‹å·²åˆ›å»º\")\n",
    "\n",
    "# æŸ¥çœ‹æ¨¡å‹æ¶æ„\n",
    "latency_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f4e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é€‰é¡¹ B: ä»…é‡åŒ–æ¨¡å‹\n",
    "from part2_optimizations import dynamic_range_quantization\n",
    "from tensorflow import keras\n",
    "\n",
    "# åŠ è½½æ¨¡å‹\n",
    "model = keras.models.load_model('baseline_mobilenetv2.keras')\n",
    "\n",
    "# åº”ç”¨åŠ¨æ€é‡åŒ–\n",
    "dynamic_range_quantization(model, save_path='optimized_models/test_quantized.tflite')\n",
    "print(\"âœ“ é‡åŒ–å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73676099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é€‰é¡¹ C: ä»…æ€§èƒ½åˆ†æ\n",
    "from performance_profiler import profile_model_comprehensive, print_profiling_results\n",
    "from tensorflow import keras\n",
    "from part1_baseline_model import load_and_preprocess_data\n",
    "\n",
    "# åŠ è½½æ¨¡å‹å’Œæ•°æ®\n",
    "model = keras.models.load_model('baseline_mobilenetv2.keras')\n",
    "_, _, test_ds = load_and_preprocess_data(batch_size=64)\n",
    "\n",
    "# æ€§èƒ½åˆ†æ\n",
    "platform_config = {\n",
    "    \"power_budget_w\": 5.0,\n",
    "    \"memory_budget_mb\": 1024,\n",
    "    \"tdp_watts\": 10.0,\n",
    "}\n",
    "\n",
    "results = profile_model_comprehensive(model, test_ds, platform_config)\n",
    "print_profiling_results(results, \"Baseline Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00efae7",
   "metadata": {},
   "source": [
    "## ğŸ“ ç”Ÿæˆåˆ†ææŠ¥å‘Š\n",
    "\n",
    "æ ¹æ®è¿è¡Œç»“æœç”Ÿæˆ Part 4 åˆ†ææŠ¥å‘Šçš„æ•°æ®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd8ccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ±‡æ€»å…³é”®æŒ‡æ ‡\n",
    "import json\n",
    "\n",
    "summary = {\n",
    "    \"project\": \"MLS3 Hardware-Aware Design\",\n",
    "    \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "    \"models\": [\n",
    "        {\"name\": \"baseline\", \"path\": \"baseline_mobilenetv2.keras\"},\n",
    "        {\"name\": \"latency_optimized\", \"path\": \"optimized_models/latency_optimized.keras\"},\n",
    "        {\"name\": \"memory_optimized\", \"path\": \"optimized_models/memory_optimized.keras\"},\n",
    "        {\"name\": \"energy_optimized\", \"path\": \"optimized_models/energy_optimized.keras\"},\n",
    "    ],\n",
    "    \"quantized_models\": [\n",
    "        {\"name\": \"dynamic_quantization\", \"path\": \"optimized_models/latency_optimized_dynamic.tflite\"},\n",
    "        {\"name\": \"ptq_int8\", \"path\": \"optimized_models/latency_optimized_ptq_int8.tflite\"},\n",
    "    ],\n",
    "    \"deployment\": [\n",
    "        {\"name\": \"tflite\", \"path\": \"optimized_models/baseline.tflite\"},\n",
    "        {\"name\": \"tflite_micro\", \"path\": \"optimized_models/baseline_data.cc\"},\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ä¿å­˜æ‘˜è¦\n",
    "with open('results/project_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"âœ“ é¡¹ç›®æ‘˜è¦å·²ä¿å­˜åˆ° results/project_summary.json\")\n",
    "print(\"\\næ‘˜è¦å†…å®¹ï¼š\")\n",
    "print(json.dumps(summary, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0c3049",
   "metadata": {},
   "source": [
    "## ğŸ‰ å®Œæˆï¼\n",
    "\n",
    "### ç”Ÿæˆçš„æ–‡ä»¶ï¼š\n",
    "\n",
    "**ä¼˜åŒ–æ¨¡å‹ï¼š**\n",
    "- `optimized_models/latency_optimized.keras` - å»¶è¿Ÿä¼˜åŒ–æ¨¡å‹\n",
    "- `optimized_models/memory_optimized.keras` - å†…å­˜ä¼˜åŒ–æ¨¡å‹\n",
    "- `optimized_models/energy_optimized.keras` - èƒ½è€—ä¼˜åŒ–æ¨¡å‹\n",
    "\n",
    "**é‡åŒ–æ¨¡å‹ï¼š**\n",
    "- `optimized_models/*_dynamic.tflite` - åŠ¨æ€é‡åŒ–æ¨¡å‹\n",
    "- `optimized_models/*_ptq_int8.tflite` - INT8 PTQ æ¨¡å‹\n",
    "\n",
    "**éƒ¨ç½²æ–‡ä»¶ï¼š**\n",
    "- `optimized_models/*.tflite` - TFLite æ ¼å¼\n",
    "- `optimized_models/*_data.cc` - TFLite Micro C æ•°ç»„\n",
    "\n",
    "**ç»“æœå’Œæ—¥å¿—ï¼š**\n",
    "- `results/` - æ€§èƒ½æŒ‡æ ‡å’Œå¯¹æ¯”æŠ¥å‘Š\n",
    "- `logs/` - è®­ç»ƒå’Œæ‰§è¡Œæ—¥å¿—\n",
    "\n",
    "### ä¸‹ä¸€æ­¥ï¼š\n",
    "1. ä¸‹è½½æ‰€æœ‰ç»“æœæ–‡ä»¶ï¼ˆå·²æ‰“åŒ…åˆ° ZIPï¼‰\n",
    "2. åˆ†ææ€§èƒ½å¯¹æ¯”æ•°æ®\n",
    "3. ç¼–å†™ Part 4 ç»¼åˆåˆ†ææŠ¥å‘Š\n",
    "4. å‡†å¤‡æ¼”ç¤ºææ–™\n",
    "\n",
    "### æç¤ºï¼š\n",
    "- ä½¿ç”¨ `files.download()` ä¸‹è½½å•ä¸ªæ–‡ä»¶\n",
    "- æ‰€æœ‰ç»“æœå·²æ‰“åŒ…åˆ° ZIP æ–‡ä»¶ä¸­\n",
    "- å¯ä»¥åœ¨ Colab æ–‡ä»¶æµè§ˆå™¨ä¸­æŸ¥çœ‹æ‰€æœ‰ç”Ÿæˆçš„æ–‡ä»¶\n",
    "- å¦‚éœ€é‡æ–°è¿è¡Œï¼Œè¯· \"è¿è¡Œæ—¶\" -> \"é‡å¯å¹¶è¿è¡Œæ‰€æœ‰å•å…ƒæ ¼\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
