 Configured memory growth for 1 GPU(s)
Num GPUs Available: 1
GPU Devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
GPU memory growth configured: True
Configured memory growth for 1 GPU(s)
Attempting to download model from Hugging Face Hub: Ishiki327/Course/baseline_model.keras
baseline_model.keras: 100% 4.00M/4.00M [00:00<00:00, 5.68MB/s]Model downloaded to: /root/.cache/huggingface/hub/models--Ishiki327--Course/snapshots/42abed2eb7248df7f7d0b59fed688d166da2f55e/baseline_model.keras
Output directory created: /content/cloud_optimized_models
Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz
170498071/170498071 ━━━━━━━━━━━━━━━━━━━━ 4s 0us/step
Initializing improved mixed precision training...
Using mixed_float16 for GPU compute capability (8, 9)
Set global mixed precision policy: mixed_float16
Creating model on device: /GPU:0
Using dynamic loss scaling for mixed precision
Starting training with mixed_float16 precision...
Epoch 1/30
79/79 ━━━━━━━━━━━━━━━━━━━━ 27s 186ms/step - accuracy: 0.8248 - loss: 0.5016 - val_accuracy: 0.8520 - val_loss: 0.4683 - learning_rate: 5.0000e-04
Epoch 2/30
79/79 ━━━━━━━━━━━━━━━━━━━━ 1s 8ms/step - accuracy: 0.8611 - loss: 0.4008 - val_accuracy: 0.8540 - val_loss: 0.4456 - learning_rate: 5.0000e-04
Epoch 3/30
79/79 ━━━━━━━━━━━━━━━━━━━━ 1s 8ms/step - accuracy: 0.8637 - loss: 0.3917 - val_accuracy: 0.8610 - val_loss: 0.4289 - learning_rate: 5.0000e-04
Epoch 4/30
79/79 ━━━━━━━━━━━━━━━━━━━━ 1s 8ms/step - accuracy: 0.8751 - loss: 0.3696 - val_accuracy: 0.8410 - val_loss: 0.4581 - learning_rate: 5.0000e-04
Epoch 5/30
79/79 ━━━━━━━━━━━━━━━━━━━━ 1s 8ms/step - accuracy: 0.8773 - loss: 0.3609 - val_accuracy: 0.8470 - val_loss: 0.4389 - learning_rate: 5.0000e-04
Epoch 6/30
79/79 ━━━━━━━━━━━━━━━━━━━━ 1s 8ms/step - accuracy: 0.8793 - loss: 0.3594 - val_accuracy: 0.8385 - val_loss: 0.4685 - learning_rate: 5.0000e-04
Epoch 7/30
79/79 ━━━━━━━━━━━━━━━━━━━━ 1s 8ms/step - accuracy: 0.8915 - loss: 0.3098 - val_accuracy: 0.8550 - val_loss: 0.4306 - learning_rate: 2.5000e-04
Epoch 8/30
79/79 ━━━━━━━━━━━━━━━━━━━━ 1s 8ms/step - accuracy: 0.8974 - loss: 0.2900 - val_accuracy: 0.8525 - val_loss: 0.4387 - learning_rate: 2.5000e-04
Training completed in 31.68 seconds
Epoch 1/30 - loss: 0.5564 - accuracy: 0.8066
Epoch 2/30 - loss: 0.5118 - accuracy: 0.8418
Epoch 3/30 - loss: 0.4329 - accuracy: 0.8633
Epoch 4/30 - loss: 0.3635 - accuracy: 0.8652
Epoch 5/30 - loss: 0.3124 - accuracy: 0.8887
Epoch 6/30 - loss: 0.3550 - accuracy: 0.8926
Epoch 7/30 - loss: 0.2847 - accuracy: 0.9082
Epoch 8/30 - loss: 0.2834 - accuracy: 0.9121
Epoch 9/30 - loss: 0.2543 - accuracy: 0.9062
Epoch 10/30 - loss: 0.2469 - accuracy: 0.9121
Epoch 11/30 - loss: 0.2424 - accuracy: 0.9121
Epoch 12/30 - loss: 0.2190 - accuracy: 0.9199
Epoch 13/30 - loss: 0.2132 - accuracy: 0.9297
Epoch 14/30 - loss: 0.1797 - accuracy: 0.9473
Epoch 15/30 - loss: 0.1475 - accuracy: 0.9629
Epoch 16/30 - loss: 0.1596 - accuracy: 0.9531
Epoch 17/30 - loss: 0.1736 - accuracy: 0.9453
Epoch 18/30 - loss: 0.1408 - accuracy: 0.9512
Epoch 19/30 - loss: 0.1350 - accuracy: 0.9590
Epoch 20/30 - loss: 0.1314 - accuracy: 0.9590
Epoch 21/30 - loss: 0.1464 - accuracy: 0.9531
Epoch 22/30 - loss: 0.1279 - accuracy: 0.9570
Epoch 23/30 - loss: 0.1190 - accuracy: 0.9668
Epoch 24/30 - loss: 0.1161 - accuracy: 0.9707
Epoch 25/30 - loss: 0.1213 - accuracy: 0.9551
Epoch 26/30 - loss: 0.0934 - accuracy: 0.9766
Epoch 27/30 - loss: 0.0964 - accuracy: 0.9648
Epoch 28/30 - loss: 0.1056 - accuracy: 0.9688
Epoch 29/30 - loss: 0.0892 - accuracy: 0.9785
Epoch 30/30 - loss: 0.0824 - accuracy: 0.9766
Epoch 1/30 - loss: 0.1195 - accuracy: 0.8381
Epoch 2/30 - loss: 0.1056 - accuracy: 0.8562
Epoch 3/30 - loss: 0.1003 - accuracy: 0.8637
Epoch 4/30 - loss: 0.0992 - accuracy: 0.8671
Epoch 5/30 - loss: 0.0964 - accuracy: 0.8696
Epoch 6/30 - loss: 0.0939 - accuracy: 0.8724
Epoch 7/30 - loss: 0.0912 - accuracy: 0.8746
Epoch 8/30 - loss: 0.0885 - accuracy: 0.8798
Epoch 9/30 - loss: 0.0889 - accuracy: 0.8797
Epoch 10/30 - loss: 0.0883 - accuracy: 0.8798
Epoch 11/30 - loss: 0.0865 - accuracy: 0.8851
Epoch 12/30 - loss: 0.0858 - accuracy: 0.8839
Epoch 13/30 - loss: 0.0832 - accuracy: 0.8870
Epoch 14/30 - loss: 0.0840 - accuracy: 0.8862
Epoch 15/30 - loss: 0.0821 - accuracy: 0.8892
Epoch 16/30 - loss: 0.0810 - accuracy: 0.8896
Epoch 17/30 - loss: 0.0763 - accuracy: 0.8955
Epoch 18/30 - loss: 0.0747 - accuracy: 0.8986
Epoch 19/30 - loss: 0.0732 - accuracy: 0.9016
Epoch 20/30 - loss: 0.0730 - accuracy: 0.9001
Epoch 21/30 - loss: 0.0735 - accuracy: 0.9008
Epoch 22/30 - loss: 0.0739 - accuracy: 0.8997
Epoch 23/30 - loss: 0.0722 - accuracy: 0.9012
Epoch 24/30 - loss: 0.0719 - accuracy: 0.8990
Epoch 25/30 - loss: 0.0719 - accuracy: 0.9002
Epoch 26/30 - loss: 0.0709 - accuracy: 0.9041
Epoch 27/30 - loss: 0.0718 - accuracy: 0.9015
Epoch 28/30 - loss: 0.0701 - accuracy: 0.9025
Epoch 29/30 - loss: 0.0700 - accuracy: 0.9041
Epoch 30/30 - loss: 0.0705 - accuracy: 0.9032
Initializing knowledge distillation with GPU-first training...
Teacher model using mixed precision with loss scaling
Training teacher model (GPU preferred, CPU fallback)...
Teacher Epoch 1/23 - loss: 1.4307 - accuracy: 0.4781
Teacher Epoch 2/23 - loss: 1.0132 - accuracy: 0.6386
Teacher Epoch 3/23 - loss: 0.8412 - accuracy: 0.7045
Teacher Epoch 4/23 - loss: 0.7344 - accuracy: 0.7455
Teacher Epoch 5/23 - loss: 0.6603 - accuracy: 0.7723
Teacher Epoch 6/23 - loss: 0.6127 - accuracy: 0.7870
Teacher Epoch 7/23 - loss: 0.5696 - accuracy: 0.8042
Teacher Epoch 8/23 - loss: 0.5317 - accuracy: 0.8166
Teacher Epoch 9/23 - loss: 0.5069 - accuracy: 0.8258
Teacher Epoch 10/23 - loss: 0.4831 - accuracy: 0.8325
Teacher Epoch 11/23 - loss: 0.4619 - accuracy: 0.8418
Teacher Epoch 12/23 - loss: 0.4426 - accuracy: 0.8470
Teacher Epoch 13/23 - loss: 0.4239 - accuracy: 0.8553
Teacher Epoch 14/23 - loss: 0.4148 - accuracy: 0.8564
Teacher Epoch 15/23 - loss: 0.3957 - accuracy: 0.8619
Teacher Epoch 16/23 - loss: 0.3854 - accuracy: 0.8669
Teacher Epoch 17/23 - loss: 0.3737 - accuracy: 0.8714
Teacher Epoch 18/23 - loss: 0.3711 - accuracy: 0.8729
Teacher Epoch 19/23 - loss: 0.3485 - accuracy: 0.8796
Teacher Epoch 20/23 - loss: 0.3486 - accuracy: 0.8796
Teacher Epoch 21/23 - loss: 0.3376 - accuracy: 0.8833
Teacher Epoch 22/23 - loss: 0.3294 - accuracy: 0.8862
Teacher Epoch 23/23 - loss: 0.3227 - accuracy: 0.8867
Teacher model saved to: /content/cloud_optimized_models/teacher_model_trained.keras
Skipping batch norm calibration due to GPU instability
Creating student model...
Successfully initialized student weights from baseline model
Student model using mixed precision with loss scaling
Starting knowledge distillation training for 30 epochs...
Using loss scaling for knowledge distillation with mixed precision
Epoch 1/30 - Loss: 1.8885 - Val Acc: 0.3662
Epoch 2/30 - Loss: 1.4810 - Val Acc: 0.3568
Epoch 3/30 - Loss: 1.2955 - Val Acc: 0.5110
Epoch 4/30 - Loss: 3.8135 - Val Acc: 0.5152
Epoch 5/30 - Loss: 3.1972 - Val Acc: 0.5806
Epoch 6/30 - Loss: 2.8946 - Val Acc: 0.6018
Epoch 7/30 - Loss: 2.7026 - Val Acc: 0.6326
Epoch 8/30 - Loss: 2.6097 - Val Acc: 0.6248
Epoch 9/30 - Loss: 2.5357 - Val Acc: 0.6332
Epoch 10/30 - Loss: 2.4604 - Val Acc: 0.6330
Epoch 11/30 - Loss: 2.3895 - Val Acc: 0.6528
Epoch 12/30 - Loss: 2.3330 - Val Acc: 0.6546
Epoch 13/30 - Loss: 2.2667 - Val Acc: 0.6598
Epoch 14/30 - Loss: 2.2416 - Val Acc: 0.6634
Epoch 15/30 - Loss: 2.2160 - Val Acc: 0.6758
Epoch 16/30 - Loss: 2.1887 - Val Acc: 0.6616
Epoch 17/30 - Loss: 2.1761 - Val Acc: 0.6816
Epoch 18/30 - Loss: 2.1406 - Val Acc: 0.6846
Epoch 19/30 - Loss: 2.1364 - Val Acc: 0.6842
Epoch 20/30 - Loss: 2.1223 - Val Acc: 0.6888
Epoch 21/30 - Loss: 2.1081 - Val Acc: 0.6910
Epoch 22/30 - Loss: 2.0939 - Val Acc: 0.6852
Epoch 23/30 - Loss: 2.1023 - Val Acc: 0.6910
Epoch 24/30 - Loss: 2.0872 - Val Acc: 0.6888
Epoch 25/30 - Loss: 2.0798 - Val Acc: 0.6938
Epoch 26/30 - Loss: 2.0880 - Val Acc: 0.6936
Epoch 27/30 - Loss: 2.0724 - Val Acc: 0.6924
Epoch 28/30 - Loss: 2.0833 - Val Acc: 0.6934
Epoch 29/30 - Loss: 2.0789 - Val Acc: 0.6936
Epoch 30/30 - Loss: 2.0795 - Val Acc: 0.6938
Teacher model saved to: /content/cloud_optimized_models/teacher_model_final.keras
Student model saved to: /content/cloud_optimized_models/student_model_distilled.keras

Cloud Optimization Results:
- Mixed Precision: policy=mixed_float16 | loss_scale=1.00 | synthetic_step_time=0.0000s | success=True
- Model Parallelism [simulated_mirrored]: workers=2
  Throughput: 200.94 samples/s
  Last Epoch -> loss=0.0824, acc=0.9766
- Batch Processing: effective_batch_size=256 (micro=64 x steps=4)
  Last Epoch -> loss=0.0705, acc=0.9032
- Knowledge Distillation:
  Teacher: [teacher_model] accuracy: 0.8712
  Student: [student_model] accuracy: 0.7012
  Student training history (last 3 epochs):
    Student Epoch 28: loss=2.0833, acc=0.6934
    Student Epoch 29: loss=2.0789, acc=0.6936
    Student Epoch 30: loss=2.0795, acc=0.6938
